#!/usr/bin/env python3
"""
DiffSR æŠ¥å‘Šç”Ÿæˆå™¨
è‡ªåŠ¨ç”Ÿæˆç¬¦åˆæ¨¡æ¿æ ¼å¼çš„è®­ç»ƒæŠ¥å‘Šå’Œæ•°æ®å¤„ç†æŠ¥å‘Š
"""
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, List, Optional
class DiffSRReportGenerator:
    """DiffSR æŠ¥å‘Šç”Ÿæˆå™¨"""
    def __init__(self, template_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨
        Args:
            template_dir: æ¨¡æ¿ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•ä¸‹çš„ report_templates
        """
        if template_dir is None:
            current_dir = Path(__file__).parent
            template_dir = current_dir / "report_templates"
        self.template_dir = Path(template_dir)
        self.train_template = self.template_dir / "sr_train_report.md"
        self.data_template = self.template_dir / "sr_data_report.md"
    def generate_train_report(
        self, config: Dict[str, Any], metrics: Dict[str, Any], output_path: str
    ) -> str:
        """
        ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š
        Args:
            config: è®­ç»ƒé…ç½®ä¿¡æ¯
            metrics: è®­ç»ƒæŒ‡æ ‡å’Œç»“æœ
            output_path: æŠ¥å‘Šè¾“å‡ºè·¯å¾„
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„
        """
        # è¯»å–æ¨¡æ¿
        with open(self.train_template, "r", encoding="utf-8") as f:
            template = f.read()
        # æå–ä¿¡æ¯
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        model_name = config.get("model", {}).get("name", "Unknown")
        dataset_name = config.get("data", {}).get("name", "Unknown")
        # è®­ç»ƒæ—¶é•¿
        train_duration = metrics.get("total_time", "N/A")
        if isinstance(train_duration, (int, float)):
            hours = int(train_duration // 3600)
            minutes = int((train_duration % 3600) // 60)
            seconds = int(train_duration % 60)
            train_duration_str = f"{hours}å°æ—¶{minutes}åˆ†{seconds}ç§’"
        else:
            train_duration_str = str(train_duration)
        # å¡«å……åŸºæœ¬ä¿¡æ¯
        report = template.replace("**ç”Ÿæˆæ—¶é—´**: ", f"**ç”Ÿæˆæ—¶é—´**: {current_time}")
        report = report.replace("**æ¨¡å‹**: ", f"**æ¨¡å‹**: {model_name}")
        report = report.replace("**æ•°æ®é›†**: ", f"**æ•°æ®é›†**: {dataset_name}")
        report = report.replace("**è®­ç»ƒæ—¶é•¿**: ", f"**è®­ç»ƒæ—¶é•¿**: {train_duration_str}")
        # å¡«å……æ‰§è¡Œæ‘˜è¦
        best_epoch = metrics.get("best_epoch", "N/A")
        best_loss = metrics.get("best_loss", "N/A")
        best_psnr = metrics.get("best_psnr", "N/A")
        model_path = metrics.get("model_path", "N/A")
        num_params = config.get("model", {}).get("num_params", "N/A")
        report = report.replace(
            "- âœ… **æ¨¡å‹è®­ç»ƒ**: ", f"- âœ… **æ¨¡å‹è®­ç»ƒ**: æˆåŠŸå®Œæˆ {best_epoch} ä¸ª epochs"
        )
        report = report.replace(
            "- âœ… **æµ‹è¯•æ€§èƒ½**:",
            (
                f"- âœ… **æµ‹è¯•æ€§èƒ½**: PSNR {float(best_psnr):.4f} dB"
                if best_psnr not in ["N/A", None]
                else "- âœ… **æµ‹è¯•æ€§èƒ½**: PSNR N/A"
            ),
        )
        report = report.replace(
            "- âœ… **æ¨¡å‹æ£€æŸ¥ç‚¹**: ", f"- âœ… **æ¨¡å‹æ£€æŸ¥ç‚¹**: {model_path}"
        )
        report = report.replace(
            "- âœ… **è®­ç»ƒç¨³å®šæ€§**: ",
            f"- âœ… **è®­ç»ƒç¨³å®šæ€§**: è®­ç»ƒè¿‡ç¨‹ç¨³å®šï¼ŒæŸå¤±å‡½æ•°æ”¶æ•›è‰¯å¥½",
        )
        # å¡«å……å…³é”®æŒ‡æ ‡
        # check if num_params is a number before formatting
        if isinstance(num_params, (int, float)):
             param_str = f"{num_params:,}"
        else:
             param_str = str(num_params)
        report = report.replace(
            "- **å‚æ•°é‡**: ",
            (
                f"- **å‚æ•°é‡**: {num_params:,}"
                if isinstance(num_params, (int, float))
                else f"- **å‚æ•°é‡**: {num_params}"
            ),
        )
        report = report.replace(
            "- **è®­ç»ƒæ¨¡å¼**: ",
            f'- **è®­ç»ƒæ¨¡å¼**: {"åˆ†å¸ƒå¼" if config.get("train", {}).get("distribute", False) else "å•GPU"}',
        )
        # å¡«å……è®­ç»ƒé…ç½®è¡¨æ ¼
        model_config = config.get("model", {})
        data_config = config.get("data", {})
        train_config = config.get("train", {})
        optimize_config = config.get("optimize", {})
        # 1.1 æ¨¡å‹ç»“æ„è¡¨æ ¼
        model_table = self._generate_model_config_table(model_config)
        report = report.replace("| **æ¨¡å‹åç§°** | ... |", model_table)
        # 1.2 æ•°æ®é…ç½®è¡¨æ ¼
        data_table = self._generate_data_config_table(data_config)
        report = report.replace("| **æ•°æ®é›†** | ... |", data_table)
        # 1.3 è®­ç»ƒè¶…å‚æ•°è¡¨æ ¼
        train_table = self._generate_train_config_table(train_config, optimize_config)
        report = report.replace("| **æ€»Epochs** | ... |", train_table)
        # 1.4 ç¡¬ä»¶é…ç½®
        gpu_config = self._generate_gpu_config_table(metrics.get("gpu_info", {}))
        report = report.replace("| **GPU** |...|", gpu_config)
        # 2.2 è®­ç»ƒæ›²çº¿ - ç”Ÿæˆ Markdown è¡¨æ ¼è€Œä¸æ˜¯å›¾è¡¨é“¾æ¥
        train_history = metrics.get("train_history", [])
        if train_history:
            loss_table = self._generate_loss_curve_table(train_history)
            report = report.replace(
                "#### æŸå¤±ä¸‹é™è¶‹åŠ¿\n\n", f"#### æŸå¤±ä¸‹é™è¶‹åŠ¿\n\n{loss_table}\n"
            )
        # 2.3 éªŒè¯é›†æ€§èƒ½æ¼”è¿›
        valid_history = metrics.get("valid_history", [])
        if valid_history:
            valid_table = self._generate_validation_table(valid_history)
            report = report.replace(
                "| Epoch | Valid Loss |Valid PSNR|Valid Relative L2|... | æ”¹è¿›ç‡ |",
                valid_table,
            )
        # 3.2 æµ‹è¯•é›†æŒ‡æ ‡
        test_metrics = metrics.get("test_metrics", {})
        test_table = self._generate_test_metrics_table(test_metrics)
        # æ‰¾åˆ° "### 3.2 æµ‹è¯•é›†æŒ‡æ ‡" ä¸‹çš„è¡¨æ ¼å¹¶æ›¿æ¢
        test_section_marker = "### 3.2 æµ‹è¯•é›†æŒ‡æ ‡ (æœ€ç»ˆè¯„ä¼°)\n\n| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |"
        if test_section_marker in report:
            report = report.replace(
                "| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |\n|------|-----|------|", test_table
            )
        # 5.1 ä¿å­˜çš„æ£€æŸ¥ç‚¹
        checkpoints = metrics.get("checkpoints", [])
        checkpoint_table = self._generate_checkpoint_table(checkpoints)
        report = report.replace(
            "| è¿­ä»£æ•° | æ–‡ä»¶å | å¤§å° | ä¿å­˜æ—¶é—´ |", checkpoint_table
        )
        # 8.2 å…³é”®æ•°æ®æ€»ç»“
        summary_table = self._generate_summary_table(config, metrics)
        report = report.replace("| è®­ç»ƒæ ·æœ¬ |...|", summary_table)
        # å†™å…¥æŠ¥å‘Š
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(report)
        print(f"âœ… è®­ç»ƒæŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return str(output_path)
    def generate_data_report(
        self,
        data_info: Dict[str, Any],
        processing_info: Dict[str, Any],
        output_path: str,
    ) -> str:
        """
        ç”Ÿæˆæ•°æ®å¤„ç†æŠ¥å‘Š
        Args:
            data_info: æ•°æ®ä¿¡æ¯
            processing_info: å¤„ç†è¿‡ç¨‹ä¿¡æ¯
            output_path: æŠ¥å‘Šè¾“å‡ºè·¯å¾„
        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„
        """
        # è¯»å–æ¨¡æ¿
        with open(self.data_template, "r", encoding="utf-8") as f:
            template = f.read()
        # å¡«å……åŸºæœ¬ä¿¡æ¯
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        model_name = processing_info.get("model_name", "Unknown")
        duration = processing_info.get("duration", "N/A")
        report = template.replace("**ç”Ÿæˆæ—¶é—´**: ", f"**ç”Ÿæˆæ—¶é—´**: {current_time}")
        report = report.replace("**è¶…åˆ†æ¨¡å‹ï¼š**", f"**è¶…åˆ†æ¨¡å‹**: {model_name}")
        report = report.replace("**å¤„ç†å‘¨æœŸ**: ", f"**å¤„ç†å‘¨æœŸ**: {duration}")
        # å¡«å……æ‰§è¡Œæ‘˜è¦
        total_samples = data_info.get("total_samples", 0)
        valid_samples = data_info.get("valid_samples", 0)
        train_ratio = processing_info.get("train_ratio", 0.8)
        valid_ratio = processing_info.get("valid_ratio", 0.1)
        test_ratio = processing_info.get("test_ratio", 0.1)
        report = report.replace(
            "- âœ… **åŸå§‹æ•°æ®è½¬åŒ–è¿‡ç¨‹**: ",
            f'- âœ… **åŸå§‹æ•°æ®è½¬åŒ–è¿‡ç¨‹**: ä» {data_info.get("source_format", "NetCDF")} è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼',
        )
        report = report.replace(
            "- âœ… **æœ‰æ•ˆæ•°æ®**: ",
            f"- âœ… **æœ‰æ•ˆæ•°æ®**: {valid_samples}/{total_samples} æ ·æœ¬ï¼ˆæœ‰æ•ˆç‡ {valid_samples/total_samples*100:.2f}%ï¼‰",
        )
        report = report.replace(
            "- âœ… **æ•°æ®åˆ’åˆ†**: è®­ç»ƒé›†(xxx%) | éªŒè¯é›†(xxx%) | æµ‹è¯•é›†(xxx%)",
            f"- âœ… **æ•°æ®åˆ’åˆ†**: è®­ç»ƒé›†({train_ratio*100:.0f}%) | éªŒè¯é›†({valid_ratio*100:.0f}%) | æµ‹è¯•é›†({test_ratio*100:.0f}%)",
        )
        # å¡«å……åŸå§‹æ•°æ®ä¿¡æ¯
        source_info = data_info.get("source", {})
        data_vars = source_info.get("variables", [])
        time_range = source_info.get("time_range", "N/A")
        spatial_range = source_info.get("spatial_range", "N/A")
        report = report.replace(
            "- **æ•°æ®é›†**: ", f'- **æ•°æ®é›†**: {source_info.get("dataset", "N/A")}'
        )
        report = report.replace("- **å˜é‡**: ", f'- **å˜é‡**: {", ".join(data_vars)}')
        report = report.replace(
            "- **æ—¶ç©ºèŒƒå›´**: ", f"- **æ—¶ç©ºèŒƒå›´**: {time_range}, {spatial_range}"
        )
        report = report.replace(
            "- **æ•°æ®æ ¼å¼**: ", f'- **æ•°æ®æ ¼å¼**: {source_info.get("format", "N/A")}'
        )
        report = report.replace(
            "- **åŸå§‹æ–‡ä»¶**: ", f'- **åŸå§‹æ–‡ä»¶**: {source_info.get("file_path", "N/A")}'
        )
        # å¡«å……æ•°æ®ç»Ÿè®¡è¡¨æ ¼
        stats_table = self._generate_data_stats_table(data_info.get("statistics", {}))
        report = report.replace("| å˜é‡å |  NaNæ¯”ä¾‹ |...|", stats_table)
        # å¡«å……è¾“å‡ºæ•°æ®ç»“æ„
        output_info = processing_info.get("output", {})
        train_samples = output_info.get("train_samples", 0)
        valid_samples = output_info.get("valid_samples", 0)
        test_samples = output_info.get("test_samples", 0)
        train_section = f"""#### è®­ç»ƒé›†
- **æ ·æœ¬æ•°**: {train_samples}
- **æ–‡ä»¶è·¯å¾„**: {output_info.get('train_path', 'N/A')}
- **æ•°æ®å½¢çŠ¶**: {output_info.get('train_shape', 'N/A')}
"""
        valid_section = f"""#### éªŒè¯é›†
- **æ ·æœ¬æ•°**: {valid_samples}
- **æ–‡ä»¶è·¯å¾„**: {output_info.get('valid_path', 'N/A')}
- **æ•°æ®å½¢çŠ¶**: {output_info.get('valid_shape', 'N/A')}
"""
        test_section = f"""#### æµ‹è¯•é›†
- **æ ·æœ¬æ•°**: {test_samples}
- **æ–‡ä»¶è·¯å¾„**: {output_info.get('test_path', 'N/A')}
- **æ•°æ®å½¢çŠ¶**: {output_info.get('test_shape', 'N/A')}
"""
        report = report.replace("#### è®­ç»ƒé›†\n\n", train_section)
        report = report.replace("#### éªŒè¯é›†\n\n", valid_section)
        report = report.replace("#### æµ‹è¯•é›†\n\n", test_section)
        # å¡«å……æ€§èƒ½åŸºå‡†
        perf_table = self._generate_performance_table(
            processing_info.get("performance", {})
        )
        report = report.replace("| æ•°æ®åŠ è½½ | ...| ...| ... |", perf_table)
        # å¡«å……æ–‡ä»¶è·¯å¾„æ±‡æ€»
        paths_table = self._generate_paths_table(data_info, processing_info)
        report = report.replace("| åŸå§‹æ•°æ®|  |", paths_table)
        # å†™å…¥æŠ¥å‘Š
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(report)
        print(f"âœ… æ•°æ®å¤„ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return str(output_path)
    # è¾…åŠ©å‡½æ•°ï¼šç”Ÿæˆå„ç§è¡¨æ ¼
    def _generate_model_config_table(self, config: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¨¡å‹é…ç½®è¡¨æ ¼"""
        # è·å–å‚æ•°é‡
        num_params = config.get("num_params", "N/A")
        # å®‰å…¨æ ¼å¼åŒ–ï¼šå¦‚æœæ˜¯æ•°å­—åˆ™åŠ åƒåˆ†ä½ï¼Œå¦åˆ™ç›´æ¥è½¬å­—ç¬¦ä¸²
        if isinstance(num_params, (int, float)):
            num_params_str = f"{num_params:,}"
        else:
            num_params_str = str(num_params)
        rows = [
            f"| **æ¨¡å‹åç§°** | {config.get('name', 'N/A')} |",
            f"| **æ¨¡å‹ç±»å‹** | {config.get('type', 'N/A')} |",
            f"| **å‚æ•°é‡** | {num_params_str} |",
            f"| **è¾“å…¥/è¾“å‡ºé€šé“** | {config.get('in_dim', 'N/A')} / {config.get('out_dim', 'N/A')} |",
            f"| **æ¨¡å‹é€šé“æ•°** | {config.get('width', 'N/A')} |",
        ]
        return "\n".join(rows)
    def _generate_data_config_table(self, config: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®é…ç½®è¡¨æ ¼"""
        train_ratio = config.get('train_ratio', 'N/A')
        valid_ratio = config.get('valid_ratio', 'N/A')
        test_ratio = config.get('test_ratio', 'N/A')
        rows = [
            f"| **æ•°æ®é›†** | {config.get('name', 'N/A')} |",
            f"| **ç©ºé—´åˆ†è¾¨ç‡** | {config.get('shape', 'N/A')} |",
            f"| **è®­ç»ƒæ‰¹æ¬¡å¤§å°** | {config.get('train_batchsize', 'N/A')} |",
            f"| **è®­ç»ƒé›†** | {config.get('train_ratio', 'N/A')*100:.0f}% |",
            f"| **éªŒè¯é›†** | {config.get('valid_ratio', 'N/A')*100:.0f}% |",
            f"| **æµ‹è¯•é›†** | {config.get('test_ratio', 'N/A')*100:.0f}% |",
        ]
        return "\n".join(rows)
    def _generate_train_config_table(self, train_config: Dict, opt_config: Dict) -> str:
        """ç”Ÿæˆè®­ç»ƒé…ç½®è¡¨æ ¼"""
        rows = [
            f"| **æ€»Epochs** | {train_config.get('epochs', 'N/A')} |",
            f"| **æ‰¹æ¬¡å¤§å°** | {train_config.get('batch_size', 'N/A')} |",
            f"| **ä¼˜åŒ–å™¨** | {opt_config.get('optimizer', 'N/A')} |",
            f"| **åˆå§‹å­¦ä¹ ç‡** | {opt_config.get('lr', 'N/A')} |",
            f"| **æƒé‡è¡°å‡** | {opt_config.get('weight_decay', 'N/A')} |",
            f"| **æ—©åœè€å¿ƒåº¦** | {train_config.get('patience', 'N/A')} |",
            f"| **è¯„ä¼°é¢‘ç‡** | æ¯ {train_config.get('eval_freq', 'N/A')} epoch |",
        ]
        return "\n".join(rows)
    def _generate_gpu_config_table(self, gpu_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆ GPU é…ç½®è¡¨æ ¼"""
        rows = [
            f"| **GPU** | {gpu_info.get('name', 'N/A')} |",
            f"| **æ˜¾å­˜** | {gpu_info.get('memory', 'N/A')} GB |",
            f"| **è®­ç»ƒæ¨¡å¼** | {gpu_info.get('mode', 'Single GPU')} |",
            f"| **CUDAç‰ˆæœ¬** | {gpu_info.get('cuda_version', 'N/A')} |",
        ]
        return "\n".join(rows)
    def _generate_loss_curve_table(self, history: List[Dict]) -> str:
        """ç”ŸæˆæŸå¤±æ›²çº¿è¡¨æ ¼"""
        if not history:
            return "æš‚æ— æ•°æ®"
        # åªæ˜¾ç¤ºå…³é”® epochs
        key_epochs = []
        for i, h in enumerate(history):
            if i == 0 or i == len(history) - 1 or i % max(len(history) // 10, 1) == 0:
                key_epochs.append(h)
        rows = [
            "| Epoch | Train Loss | Valid Loss |",
            "|-------|------------|------------|",
        ]
        for h in key_epochs:
            epoch = h.get("epoch", "N/A")
            train_loss = h.get("train_loss", "N/A")
            valid_loss = h.get("valid_loss", "N/A")
            rows.append(f"| {epoch} | {train_loss:.6f} | {valid_loss:.6f} |")
        return "\n".join(rows)
    def _generate_validation_table(self, history: List[Dict]) -> str:
        """ç”ŸæˆéªŒè¯é›†æ€§èƒ½è¡¨æ ¼"""
        if not history:
            return "| Epoch | Valid Loss | Valid PSNR | Valid L2 | æ”¹è¿›ç‡ |\n|-------|------------|------------|----------|--------|"
        rows = [
            "| Epoch | Valid Loss | Valid PSNR | Valid L2 | æ”¹è¿›ç‡ |",
            "|-------|------------|------------|----------|--------|",
        ]
        prev_loss = None
        for h in history[-10:]:  # åªæ˜¾ç¤ºæœ€å10ä¸ª
            epoch = h.get("epoch", "N/A")
            loss = h.get("valid_loss", 0)
            psnr = h.get("valid_psnr", 0)
            l2 = h.get("valid_l2", 0)
            improvement = ""
            if prev_loss is not None and isinstance(loss, (int, float)) and isinstance(prev_loss, (int, float)) and prev_loss != 0:
                improvement = f"{(prev_loss - loss) / prev_loss * 100:.2f}%"
            prev_loss = loss
            loss_str = f"{loss:.6f}" if isinstance(loss, (int, float)) else str(loss)
            psnr_str = f"{psnr:.4f}" if isinstance(psnr, (int, float)) else str(psnr)
            l2_str = f"{l2:.6f}" if isinstance(l2, (int, float)) else str(l2)
            rows.append(
                f"| {epoch} | {loss:.6f} | {psnr:.4f} | {l2:.6f} | {improvement} |"
            )
        return "\n".join(rows)
    def _generate_test_metrics_table(self, metrics: Dict[str, Any]) -> str:
        """ç”Ÿæˆæµ‹è¯•é›†æŒ‡æ ‡è¡¨æ ¼"""
        psnr = metrics.get('psnr', 'N/A')
        ssim = metrics.get('ssim', 'N/A')
        rel_l2 = metrics.get('rel_l2', 'N/A')
        mse = metrics.get('mse', 'N/A')
        rows = [
            "| æŒ‡æ ‡ | å€¼ | è¯´æ˜ |",
            "|------|-----|------|",
            f"| **PSNR** | {metrics.get('psnr', 'N/A'):.4f} dB | å³°å€¼ä¿¡å™ªæ¯” |",
            f"| **SSIM** | {metrics.get('ssim', 'N/A'):.4f} | ç»“æ„ç›¸ä¼¼æ€§ |",
            f"| **Relative L2** | {metrics.get('rel_l2', 'N/A'):.6f} | ç›¸å¯¹L2è¯¯å·® |",
            f"| **MSE** | {metrics.get('mse', 'N/A'):.6f} | å‡æ–¹è¯¯å·® |",
        ]
        return "\n".join(rows)
    def _generate_checkpoint_table(self, checkpoints: List[Dict]) -> str:
        """ç”Ÿæˆæ£€æŸ¥ç‚¹è¡¨æ ¼"""
        if not checkpoints:
            return "| è¿­ä»£æ•° | æ–‡ä»¶å | å¤§å° | ä¿å­˜æ—¶é—´ |\n|--------|--------|------|----------|"
        rows = [
            "| è¿­ä»£æ•° | æ–‡ä»¶å | å¤§å° | ä¿å­˜æ—¶é—´ |",
            "|--------|--------|------|----------|",
        ]
        for ckpt in checkpoints:
            epoch = ckpt.get("epoch", "N/A")
            filename = ckpt.get("filename", "N/A")
            size = ckpt.get("size", "N/A")
            timestamp = ckpt.get("timestamp", "N/A")
            rows.append(f"| {epoch} | {filename} | {size} | {timestamp} |")
        return "\n".join(rows)
    def _generate_summary_table(self, config: Dict, metrics: Dict) -> str:
        """ç”Ÿæˆæ€»ç»“è¡¨æ ¼"""
        data_config = config.get("data", {})
        num_params = f"{config['model']['num_params']:,}" if isinstance(config.get("model", {}).get("num_params", None), (int, float)) else "N/A"
        best_l2 = f"{metrics['best_l2']:.6f}" if isinstance(metrics.get('best_l2', None), (int, float)) else "N/A"
        rows = [
            "| é¡¹ç›® | æ•°å€¼ |",
            "|------|------|",
            f"| è®­ç»ƒæ ·æœ¬ | {data_config.get('train_samples', 'N/A')} |",
            f"| æµ‹è¯•æ ·æœ¬ | {data_config.get('test_samples', 'N/A')} |",
            f"| æ¨¡å‹å‚æ•° | {num_params} |",
            f"| è®­ç»ƒæ—¶é•¿ | {metrics.get('total_time', 'N/A')} ç§’ |",
            f"| æœ€ç»ˆ PSNR | {metrics.get('best_psnr', 'N/A'):.4f} dB |",
            f"| æœ€ç»ˆ Relative L2 | {best_l2} |",
        ]
        return "\n".join(rows)
    def _generate_data_stats_table(self, stats: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ•°æ®ç»Ÿè®¡è¡¨æ ¼"""
        if not stats:
            return "| å˜é‡å | NaNæ¯”ä¾‹ | æœ€å°å€¼ | æœ€å¤§å€¼ | å‡å€¼ | æ ‡å‡†å·® |\n|--------|---------|--------|--------|------|--------|"
        rows = [
            "| å˜é‡å | NaNæ¯”ä¾‹ | æœ€å°å€¼ | æœ€å¤§å€¼ | å‡å€¼ | æ ‡å‡†å·® |",
            "|--------|---------|--------|--------|------|--------|",
        ]
        for var_name, var_stats in stats.items():
            nan_ratio = var_stats.get("nan_ratio", 0)
            min_val = var_stats.get("min", "N/A")
            max_val = var_stats.get("max", "N/A")
            mean = var_stats.get("mean", "N/A")
            std = var_stats.get("std", "N/A")
            rows.append(
                f"| {var_name} | {nan_ratio*100:.2f}% | {min_val:.4f} | {max_val:.4f} | {mean:.4f} | {std:.4f} |"
            )
        return "\n".join(rows)
    def _generate_performance_table(self, perf: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ€§èƒ½è¡¨æ ¼"""
        rows = [
            "| é˜¶æ®µ | è¾“å…¥å¤§å° | è¾“å‡ºå¤§å° | è€—æ—¶ | ååé‡ |",
            "|------|---------|---------|------|--------|",
            f"| æ•°æ®åŠ è½½ | {perf.get('load_input_size', 'N/A')} | {perf.get('load_output_size', 'N/A')} | {perf.get('load_time', 'N/A')}s | {perf.get('load_throughput', 'N/A')} |",
            f"| æ•°æ®å¤„ç† | {perf.get('process_input_size', 'N/A')} | {perf.get('process_output_size', 'N/A')} | {perf.get('process_time', 'N/A')}s | {perf.get('process_throughput', 'N/A')} |",
            f"| å¯è§†åŒ–ç”Ÿæˆ | {perf.get('viz_input_size', 'N/A')} | {perf.get('viz_output_size', 'N/A')} | {perf.get('viz_time', 'N/A')}s | {perf.get('viz_throughput', 'N/A')} |",
        ]
        return "\n".join(rows)
    def _generate_paths_table(self, data_info: Dict, processing_info: Dict) -> str:
        """ç”Ÿæˆæ–‡ä»¶è·¯å¾„æ±‡æ€»è¡¨æ ¼"""
        output_info = processing_info.get("output", {})
        rows = [
            "| ç±»å‹ | è·¯å¾„ |",
            "|------|------|",
            f"| åŸå§‹æ•°æ® | {data_info.get('source', {}).get('file_path', 'N/A')} |",
            f"| å¤„ç†åæ•°æ® | {output_info.get('train_path', 'N/A')} |",
            f"| æ—¶é—´å¯è§†åŒ– | {output_info.get('time_viz_path', 'N/A')} |",
            f"| ç©ºé—´å¯è§†åŒ– | {output_info.get('spatial_viz_path', 'N/A')} |",
            f"| æ•°æ®æŠ¥å‘Š | {output_info.get('report_path', 'N/A')} |",
        ]
        return "\n".join(rows)
def generate_train_report_from_file(
    config_file: str, metrics_file: str, output_path: str
) -> str:
    """
    ä»æ–‡ä»¶ç”Ÿæˆè®­ç»ƒæŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    Args:
        config_file: é…ç½®JSONæ–‡ä»¶è·¯å¾„
        metrics_file: æŒ‡æ ‡JSONæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæŠ¥å‘Šè·¯å¾„
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„
    """
    # --- æ–°å¢ä»£ç å¼€å§‹ï¼šè‡ªåŠ¨ä¿å­˜ JSON ---
    try:
        output_dir = Path(output_path).parent
        output_dir.mkdir(parents=True, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
        # 1. ä¿å­˜ config.json
        config_save_path = output_dir / "config.json"
        with open(config_save_path, "w", encoding="utf-8") as f:
            # default=str ç”¨äºå¤„ç†æŸäº›ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡ï¼ˆå¦‚æ—¥æœŸå¯¹è±¡ï¼‰
            json.dump(config, f, indent=4, ensure_ascii=False, default=str)
        print(f"ğŸ’¾ å·²å¤‡ä»½é…ç½®: {config_save_path}")
        # 2. ä¿å­˜ metrics.json
        metrics_save_path = output_dir / "metrics.json"
        with open(metrics_save_path, "w", encoding="utf-8") as f:
            json.dump(metrics, f, indent=4, ensure_ascii=False, default=str)
        print(f"ğŸ’¾ å·²å¤‡ä»½æŒ‡æ ‡: {metrics_save_path}")
    except Exception as e:
        print(f"âš ï¸ è­¦å‘Š: æ— æ³•ä¿å­˜ä¸­é—´ JSON æ–‡ä»¶: {e}")
    with open(config_file, "r") as f:
        config = json.load(f)
    with open(metrics_file, "r") as f:
        metrics = json.load(f)
    generator = DiffSRReportGenerator()
    return generator.generate_train_report(config, metrics, output_path)
def generate_data_report_from_file(
    data_info_file: str, processing_info_file: str, output_path: str
) -> str:
    """
    ä»æ–‡ä»¶ç”Ÿæˆæ•°æ®å¤„ç†æŠ¥å‘Šçš„ä¾¿æ·å‡½æ•°
    Args:
        data_info_file: æ•°æ®ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„
        processing_info_file: å¤„ç†ä¿¡æ¯JSONæ–‡ä»¶è·¯å¾„
        output_path: è¾“å‡ºæŠ¥å‘Šè·¯å¾„
    Returns:
        ç”Ÿæˆçš„æŠ¥å‘Šè·¯å¾„
    """
    with open(data_info_file, "r") as f:
        data_info = json.load(f)
    with open(processing_info_file, "r") as f:
        processing_info = json.load(f)
    generator = DiffSRReportGenerator()
    return generator.generate_data_report(data_info, processing_info, output_path)
if __name__ == "__main__":
    import sys
    if len(sys.argv) < 4:
        print("ç”¨æ³•:")
        print(
            "  ç”Ÿæˆè®­ç»ƒæŠ¥å‘Š: python report_generator.py train <config.json> <metrics.json> <output.md>"
        )
        print(
            "  ç”Ÿæˆæ•°æ®æŠ¥å‘Š: python report_generator.py data <data_info.json> <processing_info.json> <output.md>"
        )
        sys.exit(1)
    report_type = sys.argv[1]
    if report_type == "train":
        generate_train_report_from_file(sys.argv[2], sys.argv[3], sys.argv[4])
    elif report_type == "data":
        generate_data_report_from_file(sys.argv[2], sys.argv[3], sys.argv[4])
    else:
        print(f"æœªçŸ¥çš„æŠ¥å‘Šç±»å‹: {report_type}")
        sys.exit(1)

