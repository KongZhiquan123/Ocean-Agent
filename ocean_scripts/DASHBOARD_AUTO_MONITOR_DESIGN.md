# ğŸš€ Dashboardè‡ªåŠ¨ç›‘æ§ç³»ç»Ÿè®¾è®¡æ–¹æ¡ˆ

**é—®é¢˜**: ç°åœ¨æ¯ä¸ªè®­ç»ƒè„šæœ¬éƒ½è¦å¤åˆ¶ç²˜è´´150+è¡Œçš„DashboardClientä»£ç ï¼Œå¤ªç¹çï¼

**è§£å†³æ–¹æ¡ˆ**: åˆ›å»ºè‡ªåŠ¨åŒ–çš„ç›‘æ§ç³»ç»Ÿï¼Œè®©ç”¨æˆ·åªéœ€1-3è¡Œä»£ç å°±èƒ½é›†æˆDashboardã€‚

---

## æ–¹æ¡ˆå¯¹æ¯”

| æ–¹æ¡ˆ | ç”¨æˆ·ä»£ç é‡ | è‡ªåŠ¨åŒ–ç¨‹åº¦ | å®ç°éš¾åº¦ | æ¨èåº¦ |
|------|-----------|-----------|---------|--------|
| 1. è£…é¥°å™¨ | 1è¡Œ | â­â­â­ | ç®€å• | â­â­â­â­ |
| 2. ä¸Šä¸‹æ–‡ç®¡ç†å™¨ | 3è¡Œ | â­â­â­â­ | ç®€å• | â­â­â­â­â­ |
| 3. PyTorch Hook | 2è¡Œ | â­â­â­â­â­ | ä¸­ç­‰ | â­â­â­â­â­ |
| 4. å…¨å±€æ³¨å†Œ | 1è¡Œ | â­â­â­â­ | ç®€å• | â­â­â­â­ |
| 5. Trainerå°è£… | 5è¡Œ | â­â­â­â­â­ | å¤æ‚ | â­â­â­ |

---

## æ–¹æ¡ˆ1: è£…é¥°å™¨æ–¹å¼ (æ¨èâ­â­â­â­)

### ä½¿ç”¨æ–¹å¼

```python
from kode_ocean import monitor_training

@monitor_training(url="http://localhost:3737", clear_old_data=True)
def train():
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleRNN().to(device)
    optimizer = torch.optim.Adam(model.parameters())

    for epoch in range(100):
        # ... training code ...
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()

        # è‡ªåŠ¨æ•è·: epoch, loss, model, deviceä¿¡æ¯

    # è‡ªåŠ¨æ ‡è®°è®­ç»ƒå®Œæˆ

if __name__ == "__main__":
    train()
```

### ä¼˜ç‚¹
- âœ… åªéœ€1è¡Œä»£ç 
- âœ… ä¸ä¾µå…¥è®­ç»ƒé€»è¾‘
- âœ… æ¸…æ™°çš„å¼€å§‹/ç»“æŸæ ‡è®°

### ç¼ºç‚¹
- âŒ éš¾ä»¥æ•è·æ¯ä¸ªepochçš„è¯¦ç»†ä¿¡æ¯
- âŒ éœ€è¦æ‰‹åŠ¨yield/returnä¿¡æ¯

### å®ç°æ–¹å¼

```python
# kode_ocean/monitor.py
import functools
import torch
from .dashboard_client import DashboardClient

def monitor_training(url="http://localhost:3737", clear_old_data=True):
    """
    Decorator to automatically monitor training with Ocean Dashboard

    Usage:
        @monitor_training()
        def train():
            # ... your training code ...
            pass
    """
    def decorator(func):
        @functools.wraps(func)
        def wrapper(*args, **kwargs):
            client = DashboardClient(url)

            # Clear old data
            if clear_old_data and client.ping():
                client.clear_all()
                client.log_info("Dashboard cleared - new training session")

            # Detect GPU
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            client.log_info(f"Using device: {device}")

            if device.type == 'cuda':
                gpu_name = torch.cuda.get_device_name(0)
                client.log_info(f"GPU: {gpu_name}")

            try:
                # Run training
                result = func(*args, **kwargs)
                client.complete_training(1, 1)  # Generic completion
                client.log_info("Training completed successfully")
                return result
            except Exception as e:
                client.log_error(f"Training failed: {e}")
                client.fail_training(0, 1)
                raise

        return wrapper
    return decorator
```

---

## æ–¹æ¡ˆ2: ä¸Šä¸‹æ–‡ç®¡ç†å™¨ (æ¨èâ­â­â­â­â­)

### ä½¿ç”¨æ–¹å¼

```python
from kode_ocean import DashboardMonitor

with DashboardMonitor(url="http://localhost:3737") as monitor:
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = SimpleRNN().to(device)

    # æ³¨å†Œæ¨¡å‹ï¼ˆè‡ªåŠ¨æå–layer infoï¼‰
    monitor.register_model(model, name="SimpleRNN", params={
        "learning_rate": 0.001,
        "batch_size": 32
    })

    optimizer = torch.optim.Adam(model.parameters())

    # å¼€å§‹è®­ç»ƒ
    monitor.start_training(num_epochs=100)

    for epoch in range(100):
        # ... training code ...
        loss = criterion(output, target)

        # è®°å½•metrics
        monitor.log_epoch(epoch+1, loss=loss.item(), metrics={
            "accuracy": acc
        })

    # è‡ªåŠ¨åœ¨é€€å‡ºæ—¶æ ‡è®°å®Œæˆ
```

### ä¼˜ç‚¹
- âœ… æ¸…æ™°çš„ç”Ÿå‘½å‘¨æœŸç®¡ç†
- âœ… è‡ªåŠ¨æ¸…ç†èµ„æº
- âœ… æ”¯æŒwithè¯­å¥ï¼Œä¼˜é›…
- âœ… å¯ä»¥ç»†ç²’åº¦æ§åˆ¶

### ç¼ºç‚¹
- âŒ éœ€è¦æ‰‹åŠ¨è°ƒç”¨log_epoch

### å®ç°æ–¹å¼

```python
# kode_ocean/monitor.py
import torch
from .dashboard_client import DashboardClient
from .model_inspector import extract_layer_info

class DashboardMonitor:
    """
    Context manager for Ocean Dashboard monitoring

    Usage:
        with DashboardMonitor() as monitor:
            monitor.register_model(model)
            monitor.start_training(100)
            for epoch in range(100):
                loss = train_one_epoch()
                monitor.log_epoch(epoch+1, loss)
    """

    def __init__(self, url="http://localhost:3737", clear_old_data=True):
        self.url = url
        self.clear_old_data = clear_old_data
        self.client = DashboardClient(url)
        self.current_epoch = 0
        self.total_epochs = 0

    def __enter__(self):
        # Clear old data
        if self.clear_old_data and self.client.ping():
            self.client.clear_all()
            self.client.log_info("=" * 60)
            self.client.log_info("NEW TRAINING SESSION - Dashboard cleared")
            self.client.log_info("=" * 60)

        # Detect GPU
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.client.log_info(f"Using device: {device}")

        if device.type == 'cuda':
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            self.client.log_info(f"GPU: {gpu_name}, Memory: {gpu_memory:.2f}GB")

        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type is None:
            # Normal completion
            self.client.complete_training(self.current_epoch, self.total_epochs)
            self.client.log_info("Training completed successfully!")
        else:
            # Error occurred
            self.client.log_error(f"Training failed: {exc_val}")
            self.client.fail_training(self.current_epoch, self.total_epochs)

        # Clear GPU memory
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            self.client.log_info("GPU memory cleared")

    def register_model(self, model, name="Model", params=None):
        """Register model with automatic layer info extraction"""
        # Extract layer info automatically
        layer_info = extract_layer_info(model)

        # Count parameters
        total_params = sum(p.numel() for p in model.parameters())

        # Update dashboard
        self.client.update_model_info(
            architecture=name,
            params={
                **(params or {}),
                "total_parameters": total_params
            },
            layer_info=layer_info
        )

        self.client.log_info(f"Model registered: {name} ({total_params:,} parameters)")

    def start_training(self, num_epochs):
        """Start training session"""
        self.total_epochs = num_epochs
        self.current_epoch = 0
        self.client.start_training(num_epochs)
        self.client.log_info(f"Starting training for {num_epochs} epochs")

    def log_epoch(self, epoch, loss, metrics=None):
        """Log one epoch's metrics"""
        self.current_epoch = epoch

        # Add metric
        self.client.add_metric(epoch, loss, metrics or {})

        # Update progress
        self.client.update_epoch(epoch, self.total_epochs)

        # GPU memory monitoring
        if torch.cuda.is_available() and epoch % 10 == 0:
            allocated = torch.cuda.memory_allocated(0) / 1024**3
            self.client.log_info(f"Epoch {epoch}: GPU Memory {allocated:.2f}GB allocated")

    def add_visualization(self, title, image_path, viz_type="plot"):
        """Add visualization to dashboard"""
        self.client.add_visualization(title, image_path, viz_type)
        self.client.log_info(f"Visualization added: {title}")
```

---

## æ–¹æ¡ˆ3: PyTorch Hookè‡ªåŠ¨æ•è· (æ¨èâ­â­â­â­â­)

### ä½¿ç”¨æ–¹å¼

```python
from kode_ocean import auto_monitor

# åªéœ€è¿™ä¸€è¡Œï¼
monitor = auto_monitor(url="http://localhost:3737")

# æ­£å¸¸å†™è®­ç»ƒä»£ç 
model = SimpleRNN().to(device)
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(100):
    for batch in train_loader:
        output = model(batch)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        # è‡ªåŠ¨æ•è·loss, è‡ªåŠ¨æ›´æ–°dashboard

# è‡ªåŠ¨æ£€æµ‹è®­ç»ƒç»“æŸ
```

### ä¼˜ç‚¹
- âœ… å®Œå…¨è‡ªåŠ¨åŒ–
- âœ… é›¶ä¾µå…¥
- âœ… è‡ªåŠ¨æ•è·lossã€gradientsç­‰

### ç¼ºç‚¹
- âŒ å®ç°å¤æ‚
- âŒ å¯èƒ½å½±å“æ€§èƒ½
- âŒ éš¾ä»¥å¤„ç†è‡ªå®šä¹‰è®­ç»ƒå¾ªç¯

### å®ç°æ–¹å¼

```python
# kode_ocean/auto_monitor.py
import torch
import torch.nn as nn
from .dashboard_client import DashboardClient

class AutoMonitor:
    """
    Automatic monitoring using PyTorch hooks

    Usage:
        monitor = auto_monitor()
        # ... normal training code ...
        # Everything is captured automatically
    """

    def __init__(self, url="http://localhost:3737"):
        self.client = DashboardClient(url)
        self.client.clear_all()

        self.epoch_losses = []
        self.current_epoch = 0
        self.hooks = []

        # Hook into PyTorch
        self._install_hooks()

    def _install_hooks(self):
        """Install hooks to capture training process"""

        # Hook backward to detect training
        original_backward = torch.Tensor.backward

        def hooked_backward(self, *args, **kwargs):
            # Capture loss value
            if self.requires_grad and self.numel() == 1:
                loss_value = self.item()
                self._monitor_loss(loss_value)

            return original_backward(self, *args, **kwargs)

        torch.Tensor.backward = hooked_backward

        # Hook optimizer.step to detect epochs
        # ... (more complex)

    def _monitor_loss(self, loss):
        """Called automatically when loss.backward() is called"""
        self.epoch_losses.append(loss)

        # If we've collected enough losses, assume one epoch
        if len(self.epoch_losses) >= 50:  # heuristic
            avg_loss = sum(self.epoch_losses) / len(self.epoch_losses)
            self.current_epoch += 1

            self.client.add_metric(
                epoch=self.current_epoch,
                loss=avg_loss,
                metrics={}
            )

            self.epoch_losses = []

def auto_monitor(url="http://localhost:3737"):
    """Enable automatic monitoring"""
    return AutoMonitor(url)
```

---

## æ–¹æ¡ˆ4: å…¨å±€æ³¨å†Œ (æ¨èâ­â­â­â­)

### ä½¿ç”¨æ–¹å¼

```python
import kode_ocean

# åœ¨è„šæœ¬å¼€å¤´æ³¨å†Œä¸€æ¬¡
kode_ocean.register_dashboard("http://localhost:3737")

# ä¹‹åæ­£å¸¸è®­ç»ƒï¼Œè‡ªåŠ¨ç›‘æ§
model = SimpleRNN()
# ... training ...
```

### ä¼˜ç‚¹
- âœ… æœ€ç®€å•ï¼Œä¸€è¡Œä»£ç 
- âœ… å…¨å±€ç”Ÿæ•ˆ

### ç¼ºç‚¹
- âŒ å…¨å±€çŠ¶æ€å¯èƒ½æœ‰å‰¯ä½œç”¨
- âŒ éš¾ä»¥ç»†ç²’åº¦æ§åˆ¶

### å®ç°æ–¹å¼

```python
# kode_ocean/__init__.py
_global_monitor = None

def register_dashboard(url="http://localhost:3737", **options):
    """
    Register global dashboard monitoring

    Usage:
        import kode_ocean
        kode_ocean.register_dashboard()

        # All subsequent training will be monitored
    """
    global _global_monitor
    _global_monitor = AutoMonitor(url, **options)
    return _global_monitor

def get_monitor():
    """Get global monitor instance"""
    return _global_monitor
```

---

## æ–¹æ¡ˆ5: Trainerå°è£… (ç±»ä¼¼PyTorch Lightning)

### ä½¿ç”¨æ–¹å¼

```python
from kode_ocean import OceanTrainer

# å®šä¹‰è®­ç»ƒé€»è¾‘
class MyTrainingModule:
    def __init__(self):
        self.model = SimpleRNN()
        self.optimizer = torch.optim.Adam(self.model.parameters())
        self.criterion = nn.MSELoss()

    def training_step(self, batch):
        output = self.model(batch['input'])
        loss = self.criterion(output, batch['target'])
        return loss

# ä½¿ç”¨Trainer
module = MyTrainingModule()
trainer = OceanTrainer(
    dashboard_url="http://localhost:3737",
    max_epochs=100
)
trainer.fit(module, train_loader)
```

### ä¼˜ç‚¹
- âœ… æœ€å¼ºå¤§ï¼Œç±»ä¼¼PyTorch Lightning
- âœ… ç»Ÿä¸€çš„è®­ç»ƒæ¥å£
- âœ… æ”¯æŒåˆ†å¸ƒå¼ã€æ··åˆç²¾åº¦ç­‰é«˜çº§åŠŸèƒ½

### ç¼ºç‚¹
- âŒ éœ€è¦é‡æ„ç°æœ‰ä»£ç 
- âŒ å­¦ä¹ æˆæœ¬é«˜
- âŒ å®ç°å¤æ‚

---

## æ¨èå®ç°æ–¹æ¡ˆ

### é˜¶æ®µ1: å¿«é€Ÿæ–¹æ¡ˆï¼ˆ1-2å°æ—¶ï¼‰

å®ç°**æ–¹æ¡ˆ2ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰**ï¼š

1. åˆ›å»º `kode_ocean/monitor.py`
2. å®ç° `DashboardMonitor` ç±»
3. æä¾› `extract_layer_info()` è¾…åŠ©å‡½æ•°
4. åœ¨condaç¯å¢ƒä¸­å®‰è£…ï¼š`pip install -e .`

**ç”¨æˆ·ä»£ç ç¤ºä¾‹**:
```python
from kode_ocean import DashboardMonitor

with DashboardMonitor() as monitor:
    model = SimpleRNN()
    monitor.register_model(model, "SimpleRNN", {"lr": 0.001})
    monitor.start_training(100)

    for epoch in range(100):
        loss = train_one_epoch()
        monitor.log_epoch(epoch+1, loss)
```

### é˜¶æ®µ2: å¢å¼ºæ–¹æ¡ˆï¼ˆ2-4å°æ—¶ï¼‰

æ·»åŠ **æ–¹æ¡ˆ4ï¼ˆå…¨å±€æ³¨å†Œï¼‰**ï¼š

```python
import kode_ocean
kode_ocean.enable_auto_monitor()

# æ­£å¸¸è®­ç»ƒï¼Œè‡ªåŠ¨ç›‘æ§
```

### é˜¶æ®µ3: å®Œæ•´æ–¹æ¡ˆï¼ˆ1-2å¤©ï¼‰

å®ç°**æ–¹æ¡ˆ3ï¼ˆPyTorch Hookï¼‰**ï¼Œå®Œå…¨è‡ªåŠ¨åŒ–ã€‚

---

## è¾…åŠ©å·¥å…·ï¼šæ¨¡å‹å±‚ä¿¡æ¯è‡ªåŠ¨æå–

```python
# kode_ocean/model_inspector.py
import torch.nn as nn

def extract_layer_info(model):
    """
    Automatically extract layer information from PyTorch model

    Returns:
        List of dicts with layer details
    """
    layer_info = []

    for name, module in model.named_modules():
        if len(list(module.children())) == 0:  # Leaf modules only
            # Count parameters
            params = sum(p.numel() for p in module.parameters())

            # Get module type
            module_type = type(module).__name__

            # Try to get input/output shapes
            # (è¿™ä¸ªæ¯”è¾ƒå¤æ‚ï¼Œéœ€è¦å®é™…forwardä¸€æ¬¡æˆ–è€…ç”¨hook)

            layer_info.append({
                "name": name or "root",
                "type": module_type,
                "params": params,
                "input_shape": [],  # TODO: Need forward hook to get
                "output_shape": []  # TODO: Need forward hook to get
            })

    return layer_info
```

---

## æ–‡ä»¶ç»“æ„

```
Kode-Ocean/
â”œâ”€â”€ ocean_scripts/
â”‚   â””â”€â”€ kode_ocean/           # æ–°çš„PythonåŒ…
â”‚       â”œâ”€â”€ __init__.py       # å¯¼å‡ºå…¬å…±API
â”‚       â”œâ”€â”€ dashboard_client.py  # åŸºç¡€DashboardClient
â”‚       â”œâ”€â”€ monitor.py        # DashboardMonitor (æ–¹æ¡ˆ2)
â”‚       â”œâ”€â”€ auto_monitor.py   # AutoMonitor (æ–¹æ¡ˆ3)
â”‚       â”œâ”€â”€ decorators.py     # @monitor_training (æ–¹æ¡ˆ1)
â”‚       â”œâ”€â”€ model_inspector.py  # æ¨¡å‹å±‚ä¿¡æ¯æå–
â”‚       â””â”€â”€ trainer.py        # OceanTrainer (æ–¹æ¡ˆ5)
â”œâ”€â”€ setup.py                  # å®‰è£…è„šæœ¬
â””â”€â”€ README.md
```

---

## å®‰è£…æ–¹å¼

```bash
cd Kode-Ocean/ocean_scripts
pip install -e .
```

æˆ–è€…æ·»åŠ åˆ°condaç¯å¢ƒï¼š
```bash
conda activate agentUse
cd Kode-Ocean/ocean_scripts
pip install -e .
```

---

## æ€»ç»“

| æ–¹æ¡ˆ | ä»£ç é‡ | æ¨èåœºæ™¯ |
|------|--------|---------|
| è£…é¥°å™¨ | 1è¡Œ | ç®€å•è„šæœ¬ï¼Œä¸éœ€è¦ç»†ç²’åº¦æ§åˆ¶ |
| ä¸Šä¸‹æ–‡ç®¡ç†å™¨ | 5-10è¡Œ | **æœ€æ¨è**ï¼Œå¹³è¡¡æ˜“ç”¨æ€§å’Œçµæ´»æ€§ |
| PyTorch Hook | 1è¡Œ | æƒ³è¦å®Œå…¨è‡ªåŠ¨åŒ–ï¼Œä¸åœ¨ä¹æ€§èƒ½ |
| å…¨å±€æ³¨å†Œ | 1è¡Œ | æ•´ä¸ªé¡¹ç›®ç»Ÿä¸€ç›‘æ§ |
| Trainerå°è£… | 20+è¡Œ | å¤§å‹é¡¹ç›®ï¼Œéœ€è¦ç»Ÿä¸€è®­ç»ƒæ¡†æ¶ |

**å»ºè®®å…ˆå®ç°æ–¹æ¡ˆ2ï¼ˆä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰ï¼Œå®ƒæ˜¯æœ€å®ç”¨çš„ï¼**
